{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: instaloader in /opt/anaconda3/lib/python3.7/site-packages (4.7.1)\n",
      "Requirement already satisfied: requests>=2.4 in /opt/anaconda3/lib/python3.7/site-packages (from instaloader) (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.4->instaloader) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.4->instaloader) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.4->instaloader) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.4->instaloader) (1.25.8)\n",
      "Requirement already satisfied: progress in /opt/anaconda3/lib/python3.7/site-packages (1.5)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install instaloader\n",
    "!{sys.executable} -m pip install progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Instagram password for kanarinkaprojects: ········\n",
      "Retrieved hashtag culturalemergency\n",
      "Hashtag #culturalemergency has 24 items \n",
      "Limiting download to 5 posts for testing\n",
      "#culturalemergency/2021-04-19_01-12-33_UTC.jpg [Here are some words that came…] json \n",
      "#culturalemergency/2021-04-18_22-09-22_UTC.jpg [How can we deal with crises s…] json \n",
      "#culturalemergency/2021-04-18_21-45-41_UTC.jpg [We are currently dealing with…] json \n",
      "#culturalemergency/2021-04-18_21-34-12_UTC.jpg [The United States is in a sta…] json \n",
      "#culturalemergency/2021-04-18_21-25-13_UTC.jpg [Erin Genia, Sisseton-Wahpeton…] json \n",
      "Success! Created file culturalemergency-output-04212021-063951.csv\n"
     ]
    }
   ],
   "source": [
    "# %load download_IG_hashtag.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Created on Apr 11 2021\n",
    "\n",
    "@author: kanarinka\n",
    "\"\"\"\n",
    "\n",
    "import instaloader\n",
    "from datetime import datetime\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "from progress.bar import IncrementalBar\n",
    "\n",
    "################################\n",
    "# PUT YOUR OWN VALUES HERE\n",
    "\n",
    "# Username of account you will use for logging in\n",
    "USER = \"kanarinkaprojects\"\n",
    "\n",
    "# Hashtag that you want to download IG posts from\n",
    "HASHTAG_TO_SEARCH = \"culturalemergency\"\n",
    "\n",
    "# Limit of posts to download. Limit to 10 or 20 while\n",
    "# testing or else it'll take forever. Set to -1 to get\n",
    "# everything.\n",
    "LIMIT = 5\n",
    "\n",
    "################################\n",
    "\n",
    "# Set up Instaloader instance\n",
    "L = instaloader.Instaloader()\n",
    "L.interactive_login(USER)\n",
    "\n",
    "# Set up CSV file & header row\n",
    "current_time = datetime.now().strftime(\"%m%d%Y-%H%M%S\")\n",
    "\n",
    "fname = HASHTAG_TO_SEARCH +'-output-' + current_time +'.csv'\n",
    "csvFile = open(fname, 'w', encoding=\"utf-8-sig\")\n",
    "\n",
    "fieldnames = [\n",
    "\t\t\t\t'shortcode',\n",
    "\t\t\t\t'mediaid',\n",
    "\t\t\t\t'title',\n",
    "\t\t\t\t'owner_username',\n",
    "\t\t\t\t'owner_id',\n",
    "\t\t\t\t'date_local',\n",
    "\t\t\t\t'date_utc',\n",
    "\t\t\t\t'url',\n",
    "\t\t\t\t'mediacount',\n",
    "\t\t\t\t'caption',\n",
    "\t\t\t\t'caption_hashtags',\n",
    "\t\t\t\t'caption_mentions',\n",
    "\t\t\t\t'tagged_users',\n",
    "\t\t\t\t'is_video',\n",
    "\t\t\t\t'video_url',\n",
    "\t\t\t\t'video_view_count',\n",
    "\t\t\t\t'video_duration',\n",
    "\t\t\t\t'likes',\n",
    "\t\t\t\t'comment_count',\n",
    "\t\t\t\t'users_who_commented',\n",
    "\t\t\t\t'all_comments_text',\n",
    "\t\t\t\t'is_sponsored',\n",
    "\t\t\t\t'location_id',\n",
    "\t\t\t\t'location_lat',\n",
    "\t\t\t\t'location_lng',\n",
    "\t\t\t\t'location_name'\n",
    "\t\t\t ]\n",
    "csvWriter = csv.DictWriter(csvFile, fieldnames=fieldnames, dialect=\"excel\")\n",
    "csvWriter.writeheader()\n",
    "\n",
    "\n",
    "# Retrieve hashtag object\n",
    "\n",
    "# Uncomment this after issue #1080 is fixed\n",
    "# hashtag = instaloader.Hashtag.from_name(L.context, HASHTAG_TO_SEARCH)\n",
    "# print(\"Retrieved hashtag \" + hashtag.name)\n",
    "# print(\"Hashtag #\" + hashtag.name + \" has \" + str(hashtag.mediacount) + \" items \")\n",
    "# post_count = hashtag.mediacount\n",
    "\n",
    "# in the meantime, use this workaround specified in issue #874\n",
    "post_iterator = instaloader.NodeIterator(\n",
    "    L.context, \"9b498c08113f1e09617a1703c22b2f32\",\n",
    "    lambda d: d['data']['hashtag']['edge_hashtag_to_media'],\n",
    "    lambda n: instaloader.Post(L.context, n),\n",
    "    {'tag_name': HASHTAG_TO_SEARCH},\n",
    "    f\"https://www.instagram.com/explore/tags/{HASHTAG_TO_SEARCH}/\"\n",
    ")\n",
    "\n",
    "print(\"Retrieved hashtag \" + HASHTAG_TO_SEARCH)\n",
    "print(\"Hashtag #\" + HASHTAG_TO_SEARCH + \" has \" + str(post_iterator.count) + \" items \")\n",
    "post_count = post_iterator.count\n",
    "# end workaround\n",
    "\n",
    "\n",
    "# set up progress bar because this takes awhile\n",
    "bar = IncrementalBar('Countdown', max = post_count)\n",
    "\n",
    "if LIMIT > 0:\n",
    "\tprint(\"Limiting download to \" + str(LIMIT) + \" posts for testing\")\n",
    "\tbar = IncrementalBar('Countdown', max = min(LIMIT, post_count))\n",
    "\n",
    "\n",
    "# Iterate each post and save media to disk + metadata to spreadsheet\n",
    "# for post in hashtag.get_posts():\n",
    "# WORKAROUND WITH POST ITERATOR\n",
    "for post in post_iterator:\n",
    "\t# Download the media and metadata as JSON\n",
    "\tL.download_post(post, target=\"#\"+HASHTAG_TO_SEARCH)\n",
    "\n",
    "\t# Format comments for including in CSV\n",
    "\tall_comments = post.get_comments()\n",
    "\tusers_who_commented = []\n",
    "\tall_comments_text = []\n",
    "\n",
    "\tfor comment in all_comments:\n",
    "\t\tusers_who_commented.append(comment.owner.username)\n",
    "\t\tcomment_text = str(json.loads(json.dumps(comment.text)))\n",
    "\t\tall_comments_text.append(comment_text)\n",
    "\n",
    "\t# Format caption\n",
    "\tcaption_text = str(json.loads(json.dumps(post.caption)))\n",
    "\n",
    "\t# Handle null location objects\n",
    "\tif post.location is None:\n",
    "\t\tpost_location_id = \"\"\n",
    "\t\tpost_location_lat = \"\"\n",
    "\t\tpost_location_lng = \"\"\n",
    "\t\tpost_location_name = \"\"\n",
    "\telse:\n",
    "\t\tpost_location_id = post.location.id\n",
    "\t\tpost_location_lat = post.location.lat\n",
    "\t\tpost_location_lng = post.location.lng\n",
    "\t\tpost_location_name = post.location.name\n",
    "\n",
    "\t# Assemble the row in the CSV\n",
    "\trow = {\n",
    "\t\t'shortcode': post.shortcode,\n",
    "\t\t'mediaid': post.mediaid,\n",
    "\t\t'title': post.title,\n",
    "\t\t'owner_username': post.owner_username,\n",
    "\t\t'owner_id': post.owner_id,\n",
    "\t\t'date_local': post.date_local.strftime(\"%x %X\"),\n",
    "\t\t'date_utc': post.date_utc.strftime(\"%x %X\"),\n",
    "\t\t'url': post.url,\n",
    "\t\t'mediacount': post.mediacount,\n",
    "\t\t'caption': caption_text,\n",
    "\t\t'caption_hashtags': ' '.join([str(elem) for elem in post.caption_hashtags]),\n",
    "\t\t'caption_mentions': ' '.join([str(elem) for elem in post.caption_mentions]),\n",
    "\t\t'tagged_users': ' '.join([str(elem) for elem in post.tagged_users]),\n",
    "\t\t'is_video': post.is_video,\n",
    "\t\t'video_url': post.video_url,\n",
    "\t\t'video_view_count': post.video_view_count,\n",
    "\t\t'video_duration': post.video_duration,\n",
    "\t\t'likes': post.likes,\n",
    "\t\t'comment_count': post.comments,\n",
    "\t\t'users_who_commented':' '.join([str(elem) for elem in users_who_commented]),\n",
    "\t\t'all_comments_text': ' @@@ '.join([str(elem) for elem in all_comments_text]),\n",
    "\t\t'is_sponsored': post.is_sponsored,\n",
    "\t\t'location_id': post_location_id,\n",
    "\t\t'location_lat': post_location_lat,\n",
    "\t\t'location_lng': post_location_lng,\n",
    "\t\t'location_name': post_location_name\n",
    "\t}\n",
    "\t\n",
    "\t# Write the row into the CSV file\n",
    "\tcsvWriter.writerow(row)\n",
    "\tbar.next()\n",
    "\t\n",
    "\t# Break if LIMIT of posts has been reached\n",
    "\tif LIMIT > 0:\n",
    "\t\tLIMIT -= 1\n",
    "\tif LIMIT == 0: \n",
    "\t\tbreak\n",
    "\n",
    "#Clean up\n",
    "bar.finish()\n",
    "csvFile.close()\n",
    "print(\"Success! Created file \" + fname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
